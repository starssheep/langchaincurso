{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380f61c1",
   "metadata": {},
   "source": [
    "# Introdução ao LangSmith\n",
    "\n",
    "O LangSmith é uma plataforma para testar, depurar e avaliar aplicativos baseados em LLM.\n",
    "Neste notebook, vamos explorar os conceitos fundamentais:\n",
    "1. **Tracing**: Como visualizar o fluxo de execução das suas chains.\n",
    "2. **Datasets**: Como criar conjuntos de dados para testes.\n",
    "3. **Avaliação**: Como rodar testes automatizados nos seus datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6615df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "%pip install -qU langsmith langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335db7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# LangSmith Config\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "\n",
    "if not os.environ.get(\"LANGCHAIN_API_KEY\"):\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API Key: \")\n",
    "\n",
    "if not os.environ.get(\"LANGCHAIN_PROJECT\"):\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"curso-langsmith-intro\" # Nome do projeto no LangSmith\n",
    "\n",
    "# OpenAI API Key\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f0d97",
   "metadata": {},
   "source": [
    "## 1. Tracing Básico\n",
    "\n",
    "O tracing já está ativo porque definimos `LANGCHAIN_TRACING_V2=\"true\"`. Qualquer chamada feita com componentes do LangChain será registrada automaticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54035b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Simples chamada, isso vai gerar um trace\n",
    "response = llm.invoke(\"Explique o que é LangSmith em uma frase.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788bc24a",
   "metadata": {},
   "source": [
    "Vá para [smith.langchain.com](https://smith.langchain.com) e verifique o projeto `curso-langsmith-intro`. Você deve ver o trace da execução acima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8597d86",
   "metadata": {},
   "source": [
    "## 2. Datasets\n",
    "\n",
    "Datasets são coleções de exemplos (entradas e saídas esperadas) usados para testar e avaliar seu aplicativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3f3aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"Perguntas de Exemplo\"\n",
    "\n",
    "# Criar Dataset se não existir\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=\"Um dataset de exemplo com perguntas e respostas.\"\n",
    "    )\n",
    "    \n",
    "    # Adicionar exemplos\n",
    "    client.create_examples(\n",
    "        inputs=[\n",
    "            {\"pergunta\": \"Qual é a capital da França?\"},\n",
    "            {\"pergunta\": \"Quanto é 2 + 2?\"},\n",
    "            {\"pergunta\": \"Quem escreveu Dom Casmurro?\"}\n",
    "        ],\n",
    "        outputs=[\n",
    "            {\"resposta\": \"Paris\"},\n",
    "            {\"resposta\": \"4\"},\n",
    "            {\"resposta\": \"Machado de Assis\"}\n",
    "        ],\n",
    "        dataset_id=dataset.id\n",
    "    )\n",
    "    print(\"Dataset criado!\")\n",
    "else:\n",
    "    print(\"Dataset já existe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b77a9",
   "metadata": {},
   "source": [
    "## 3. Avaliação\n",
    "\n",
    "Agora vamos usar o dataset criado para avaliar nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbab566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.smith import RunEvalConfig, run_on_dataset\n",
    "\n",
    "# 1. Definir o que vamos testar (nosso \"sistema\")\n",
    "# O sistema deve aceitar a entrada do dataset e produzir uma saída.\n",
    "\n",
    "def meu_app(inputs):\n",
    "    return llm.invoke(inputs[\"pergunta\"]).content\n",
    "\n",
    "# 2. Configurar Avaliadores\n",
    "# Avaliadores \"QA\" verificam a precisão comparando com a resposta de referência (output do dataset)\n",
    "eval_config = RunEvalConfig(\n",
    "    evaluators=[\"qa\"], # usa um LLM para julgar se a resposta bate com o gabarito\n",
    ")\n",
    "\n",
    "# 3. Rodar Avaliação\n",
    "results = run_on_dataset(\n",
    "    client=client,\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=meu_app,\n",
    "    evaluation=eval_config,\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9497b4a",
   "metadata": {},
   "source": [
    "Agora você pode visualizar os resultados da avaliação no painel do LangSmith."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
