{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 24. LangGraph: Human-in-the-Loop\n",
                "\n",
                "Em sistemas críticos, não queremos que o Agente tome a decisão final sem aprovação. O LangGraph permite pausar a execução, esperar o input humano (aprovar ou editar o estado) e depois continuar.\n",
                "\n",
                "**Objetivos:**\n",
                "- Usar `MemorySaver` para persistir o estado.\n",
                "- Usar `interrupt_before` para pausar.\n",
                "- Simular uma aprovação humana."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -qU langchain langchain-openai langchain-community langgraph"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from google.colab import userdata\n",
                "import getpass\n",
                "\n",
                "try:\n",
                "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
                "except:\n",
                "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Digite sua OpenAI API Key: \")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup do Grafo Simples\n",
                "\n",
                "Um agente que escreve um e-mail."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import TypedDict\n",
                "from langgraph.graph import StateGraph, START, END\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "class State(TypedDict):\n",
                "    topic: str\n",
                "    email_draft: str\n",
                "    feedback: str\n",
                "\n",
                "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
                "\n",
                "def writer(state: State):\n",
                "    print(\"--- ESCREVENDO RASCUNHO ---\")\n",
                "    msg = f\"Escreva um e-mail curto sobre: {state['topic']}.\"\n",
                "    if state.get('feedback'):\n",
                "        msg += f\" Considere este feedback: {state['feedback']}\"\n",
                "    res = llm.invoke(msg)\n",
                "    return {\"email_draft\": res.content}\n",
                "\n",
                "def sender(state: State):\n",
                "    print(\"--- ENVIANDO E-MAIL (Simulado) ---\")\n",
                "    print(f\"ENVIADO: {state['email_draft']}\")\n",
                "    return {}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Checkpointing e Interrupção\n",
                "\n",
                "Para pausar, precisamos de um `checkpointer` (memória) e configurar `interrupt_before`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langgraph.checkpoint.memory import MemorySaver\n",
                "\n",
                "workflow = StateGraph(State)\n",
                "workflow.add_node(\"writer\", writer)\n",
                "workflow.add_node(\"sender\", sender)\n",
                "\n",
                "workflow.add_edge(START, \"writer\")\n",
                "workflow.add_edge(\"writer\", \"sender\")\n",
                "workflow.add_edge(\"sender\", END)\n",
                "\n",
                "# Checkpointer em memória\n",
                "memory = MemorySaver()\n",
                "\n",
                "# Pausar ANTES de entrar no nó 'sender'\n",
                "app = workflow.compile(checkpointer=memory, interrupt_before=[\"sender\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Rodando até a pausa\n",
                "\n",
                "Precisamos de uma `thread_id` para manter a sessão."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "thread_config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
                "\n",
                "# Roda até parar antes do 'sender'\n",
                "app.invoke({\"topic\": \"Convite para Webinar de IA\"}, config=thread_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. O Humano Intervém\n",
                "\n",
                "Agora podemos inspecionar o estado e decidir."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pegando o estado atual\n",
                "state = app.get_state(thread_config)\n",
                "print(\"RASCUNHO ATUAL:\")\n",
                "print(state.values['email_draft'])\n",
                "\n",
                "# Decisão Humana (Simulada)\n",
                "decisao = \"aprovar\" # ou \"editar\"\n",
                "\n",
                "if decisao == \"aprovar\":\n",
                "    print(\"\\nHumano: Aprovado! Continuando...\")\n",
                "    # Continuar de onde parou (None = sem novos inputs)\n",
                "    app.invoke(None, config=thread_config)\n",
                "else:\n",
                "    print(\"\\nHumano: Precisa melhorar...\")\n",
                "    # Atualizamos o estado com feedback e voltamos pro writer (seria outra logica de grafo, mas aqui é só exemplo)\n",
                "    # Para editar o estado, usaríamos app.update_state(...)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusão\n",
                "\n",
                "O `interrupt_before` é poderoso para criar sistemas seguros onde o humano tem a palavra final."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}