{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 14. Auditoria: Classificação Automática de Riscos\n",
                "\n",
                "Um dos passos da auditoria é classificar os apontamentos conforme seu risco (Alto, Médio, Baixo) para priorizar correções. LLMs são excelentes classificadores zero-shot.\n",
                "\n",
                "**Objetivo:** Classificar descrições de falhas de controle e gerar uma justificativa para a nota."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -qU langchain langchain-openai langchain-community"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from google.colab import userdata\n",
                "import getpass\n",
                "\n",
                "try:\n",
                "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
                "except:\n",
                "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Digite sua OpenAI API Key: \")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Definindo a Matriz de Riscos no Prompt\n",
                "\n",
                "Instruímos o modelo sobre o que constitui cada nível de risco."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_core.pydantic_v1 import BaseModel, Field\n",
                "\n",
                "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
                "\n",
                "# Schema de Saída\n",
                "class ClassificacaoRisco(BaseModel):\n",
                "    nivel: str = Field(description=\"Nível de risco: 'Alto', 'Médio' ou 'Baixo'\")\n",
                "    justificativa: str = Field(description=\"Explicação breve do porquê desse nível de risco\")\n",
                "    acao_sugerida: str = Field(description=\"Ação imediata recomendada\")\n",
                "\n",
                "structured_llm = llm.with_structured_output(ClassificacaoRisco)\n",
                "\n",
                "sistema = \"\"\"\n",
                "Você é um especialista em Gestão de Riscos Corporativos.\n",
                "Classifique o seguinte apontamento de auditoria interna conforme a matriz:\n",
                "\n",
                "- ALTO: Perda financeira significativa (> R$ 100k), fraude, violação legal grave (LGPD, Anticorrupção) ou risco de imagem.\n",
                "- MÉDIO: Falha de processo repetitiva, perda financeira moderada (< R$ 100k) ou dados imprecisos.\n",
                "- BAIXO: Erros pontuais, documentação faltante não crítica ou melhoria de eficiência.\n",
                "\"\"\"\n",
                "\n",
                "prompt = ChatPromptTemplate.from_messages([\n",
                "    (\"system\", sistema),\n",
                "    (\"human\", \"Apontamento: {apontamento}\")\n",
                "]) | structured_llm"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Testando com Casos Reais\n",
                "\n",
                "Vamos passar alguns cenários para ver a classificação."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cenarios = [\n",
                "    \"O sistema de almoxarifado permite saída de mercadoria sem requisição aprovada. Identificada perda de estoque de R$ 500.000 no ano.\",\n",
                "    \"Três relatórios de despesas de viagem de Junho/2023 estavam sem carimbo da recepção, mas com notas fiscais válidas.\",\n",
                "    \"Identificamos um funcionário do Depto de Compras que é sócio de um fornecedor recém-contratado sem declaração de conflito de interesses.\"\n",
                "]\n",
                "\n",
                "for cenario in cenarios:\n",
                "    print(f\"--- CENÁRIO: {cenario[:60]}... ---\")\n",
                "    res = prompt.invoke({\"apontamento\": cenario})\n",
                "    print(f\"NÍVEL: {res.nivel}\")\n",
                "    print(f\"JUSTIFICATIVA: {res.justificativa}\")\n",
                "    print(f\"AÇÃO: {res.acao_sugerida}\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Tagging Chain (Opção Alternativa)\n",
                "\n",
                "O LangChain também possui `create_tagging_chain` para casos simples onde queremos apenas categorizar (tags)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusão\n",
                "\n",
                "Automatizar a classificação inicial ajuda a direcionar o foco dos auditores seniores para os problemas de Risco Alto."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}