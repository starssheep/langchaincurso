{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25. LangGraph: Multi-Agent Supervisor\n",
    "\n",
    "O padrão mais avançado de agentes é ter múltiplos especialistas (ex: um Pesquisador, um Codificador, um Revisor) orquestrados por um Supervisor.\n",
    "\n",
    "**Objetivos:**\n",
    "- Criar agentes especialistas.\n",
    "- Criar um nó Supervisor que decide quem chamar.\n",
    "- Criar o grafo de roteamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "!pip install -qU langchain langchain-openai langchain-community langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "except ImportError:\n",
    "    userdata = None\n",
    "import getpass\n",
    "\n",
    "try:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "except:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Digite sua OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definindo os Agentes Especialistas\n",
    "\n",
    "Para simplificar, usaremos chains simples como \"agentes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "def agente_pesquisador(state):\n",
    "    print(\"--- PESQUISADOR ATUANDO ---\")\n",
    "    messages = [\n",
    "        SystemMessage(content=\"Você é um pesquisador web. Retorne dados factuais sobre o tema.\"),\n",
    "        HumanMessage(content=state['tarefa'])\n",
    "    ]\n",
    "    res = llm.invoke(messages)\n",
    "    return {\"resultado_pesquisa\": res.content, \"ultimo_agente\": \"pesquisador\"}\n",
    "\n",
    "def agente_redator(state):\n",
    "    print(\"--- REDATOR ATUANDO ---\")\n",
    "    pesquisa = state.get('resultado_pesquisa', 'Sem dados')\n",
    "    messages = [\n",
    "        SystemMessage(content=\"Você é um redator. Escreva um parágrafo elegante baseada na pesquisa.\"),\n",
    "        HumanMessage(content=f\"Tarefa original: {state['tarefa']}. Pesquisa: {pesquisa}\")\n",
    "    ]\n",
    "    res = llm.invoke(messages)\n",
    "    return {\"texto_final\": res.content, \"ultimo_agente\": \"redator\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. O Supervisor\n",
    "\n",
    "Ele decide qual o próximo passo. Usamos `with_structured_output` para forçar ele a escolher um dos agentes ou FINISH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "class DecisaoSupervisor(BaseModel):\n",
    "    proximo: Literal[\"pesquisador\", \"redator\", \"FINISH\"]\n",
    "\n",
    "supervisor_llm = llm.with_structured_output(DecisaoSupervisor)\n",
    "\n",
    "def supervisor(state):\n",
    "    print(\"--- SUPERVISOR PENSANDO ---\")\n",
    "    prompt = f\"\"\"\n",
    "    Tarefa: {state['tarefa']}\n",
    "    Último agente: {state.get('ultimo_agente')}\n",
    "    \n",
    "    Se não tiver pesquisa, chame o 'pesquisador'.\n",
    "    Se já tiver pesquisa, chame o 'redator'.\n",
    "    Se já tiver texto final ('ultimo_agente' for redator), chame 'FINISH'.\n",
    "    \"\"\"\n",
    "    decisao = supervisor_llm.invoke(prompt)\n",
    "    return {\"proximo_passo\": decisao.proximo}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Montando o Grafo\n",
    "\n",
    "Estado e roteamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class TeamState(TypedDict):\n",
    "    tarefa: str\n",
    "    resultado_pesquisa: Optional[str]\n",
    "    texto_final: Optional[str]\n",
    "    ultimo_agente: Optional[str]\n",
    "    proximo_passo: str\n",
    "\n",
    "workflow = StateGraph(TeamState)\n",
    "\n",
    "workflow.add_node(\"supervisor\", supervisor)\n",
    "workflow.add_node(\"pesquisador\", agente_pesquisador)\n",
    "workflow.add_node(\"redator\", agente_redator)\n",
    "\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "# Arestas normais: depois dos trabalhadores, volta pro supervisor decidir\n",
    "workflow.add_edge(\"pesquisador\", \"supervisor\")\n",
    "workflow.add_edge(\"redator\", \"supervisor\")\n",
    "\n",
    "# Aresta condicional saindo do supervisor\n",
    "def roteador_supervisor(state):\n",
    "    if state['proximo_passo'] == \"FINISH\":\n",
    "        return END\n",
    "    return state['proximo_passo']\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    roteador_supervisor,\n",
    "    {\n",
    "        \"pesquisador\": \"pesquisador\",\n",
    "        \"redator\": \"redator\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Executando o Time\n",
    "\n",
    "Vamos pedir para escrever sobre Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = app.invoke({\"tarefa\": \"Escreva um resumo histórico sobre a linguagem Python.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== TEXTO FINAL ===\")\n",
    "print(res['texto_final'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Criamos uma arquitetura hierárquica onde um Supervisor gerencia o fluxo entre subordinados. Este é o estado da arte em sistemas baseados em Agentes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
